{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Stemming?\n",
    "\n",
    "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP).\n",
    "\n",
    "Stemming is a part of linguistic studies in morphology and artificial intelligence (AI) information retrieval and extraction. Stemming and AI knowledge extract meaningful information from vast sources like big data or the Internet since additional forms of a word related to a subject may need to be searched to get the best results. Stemming is also a part of queries and Internet search engines.\n",
    "\n",
    "Recognizing, searching and retrieving more forms of words returns more results. When a form of a word is recognized it can make it possible to return search results that otherwise might have been missed. That additional information retrieved is why stemming is integral to search queries and information retrieval.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing stemming:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1: Importing the Libraries:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the nltk library\n",
    "\n",
    "# importing re\n",
    "\n",
    "# from nltk.stem import PorterStemmer that would actually perform stemming\n",
    "\n",
    "# from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2: Now use some paragraph on which we will be implementing stemming:-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3: Perform Tokenization:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now using sent_tokenizer tokenize the paragraph into words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4: Perform Stemming:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an empty list\n",
    "\n",
    "# Initialise a for loop ranging upto the length of the sentences\n",
    "                \n",
    "    # Now inside for loop first implement re.sub(['a-zA-Z'],' ',sentence[i])\n",
    "    \n",
    "    # Now lower the newly formed list using list.lower()\n",
    "    \n",
    "    # Now split the list of words using list.split()\n",
    "    \n",
    "    # Now remove stopwords and perform stemming\n",
    "    \n",
    "    # Using list.join() join the stemmed words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now using print command you can print the list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Lemmatization?\n",
    "\n",
    "The process of lemmatization in natural language processing involves working with words according to their root lexical components. It is used in natural language processing and natural language understanding in computer programming and artificial intelligence.\n",
    "\n",
    "Lemmatization is a bit more complex in that the computer can group together words that do not have the same stem, but still have the same inflected meaning. Grouping the word “good” with words like “better” and “best” is an example of lemmatization. Lemmatization is also a harbinger of increased artificial intelligence sophistication – as natural language processing advances in accommodating lemmatization, it is more able to parse inputs and provide intelligent outputs. This will be an important aspect of NLP as technology gets closer to passing the Turing test with computers that hear, understand, think and speak like humans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Lemmatization:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1: Importing the Libraries:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the nltk library\n",
    "\n",
    "# importing re\n",
    "\n",
    "# from nltk.stem import WordNetLemmatizer that would actually perform lemmatization\n",
    "\n",
    "# from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2: Now use some paragraph on which we will be implementing lemmatization:-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the paragraph or word or sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3: Perform Tokenization:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sent_tokenizer perform tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4: Perform Lemmatization:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an empty list\n",
    "\n",
    "# Initialise a for loop ranging upto the length of the sentences\n",
    "                \n",
    "    # Now inside for loop first implement re.sub(['a-zA-Z'],' ',sentence[i])\n",
    "    \n",
    "    # Now lower the newly formed list using list.lower()\n",
    "    \n",
    "    # Now split the list of words using list.split()\n",
    "    \n",
    "    # Now remove stopwords and perform lemmatization\n",
    "    \n",
    "    # Using list.join() join the lemmatized words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally Using Print Command you will be able to view the lemmatized list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
